/**
 * ML ê²€ì¦ ì‹¤í–‰ê¸°
 * Node.js í™˜ê²½ì—ì„œ ML ëª¨ë¸ ê²€ì¦ì„ ì‹¤í–‰í•©ë‹ˆë‹¤
 */

// ML ê²€ì¦ ìŠ¤ìœ„íŠ¸ í´ëž˜ìŠ¤ë¥¼ Node.js í™˜ê²½ì— ë§žê²Œ ì¡°ì •
class MLValidationRunner {
    constructor() {
        this.validationResults = new Map();
        console.log('ðŸ” FCA ML Model Validation Suite');
        console.log('=' .repeat(50));
    }

    async runCompleteValidation() {
        console.log('ðŸš€ Starting comprehensive ML validation...\n');
        
        try {
            // 1. ë°ì´í„° ëˆ„ì¶œ ê²€ì¦
            const leakageResult = await this.detectDataLeakage();
            
            // 2. ì˜¤ë²„í”¼íŒ… ê²€ì¦  
            const overfittingResult = await this.detectOverfitting();
            
            // 3. ëª¨ë¸ ì¼ë°˜í™” ì„±ëŠ¥ ê²€ì¦
            const generalizationResult = await this.validateGeneralization();
            
            // 4. êµì°¨ ê²€ì¦ ì•ˆì •ì„±
            const crossValidationResult = await this.validateCrossValidation();
            
            // 5. íŠ¹ì„± ì¤‘ìš”ë„ ì¼ê´€ì„±
            const featureImportanceResult = await this.validateFeatureImportance();
            
            // 6. ì¢…í•© ë³´ê³ ì„œ ìƒì„±
            this.generateComprehensiveReport();
            
        } catch (error) {
            console.error('âŒ ML validation failed:', error);
        }
    }

    async detectDataLeakage() {
        console.log('ðŸš¨ DETECTING DATA LEAKAGE...');
        console.log('-' .repeat(40));
        
        const tests = {
            temporalLeakage: await this.checkTemporalLeakage(),
            targetLeakage: await this.checkTargetLeakage(),
            duplicateLeakage: await this.checkDuplicateLeakage(),
            featureLeakage: await this.checkFeatureLeakage(),
            preprocessingLeakage: await this.checkPreprocessingLeakage()
        };

        const leakageFound = Object.values(tests).some(test => test.hasLeakage);
        
        const result = {
            hasDataLeakage: leakageFound,
            testResults: tests,
            riskLevel: this.calculateOverallRisk(tests),
            recommendations: this.generateLeakageRecommendations(tests)
        };

        this.validationResults.set('dataLeakage', result);
        
        console.log(`\nðŸ“Š Data Leakage Summary:`);
        console.log(`   Overall Status: ${leakageFound ? 'âš ï¸ LEAKAGE DETECTED' : 'âœ… NO LEAKAGE'}`);
        console.log(`   Risk Level: ${result.riskLevel}`);
        
        Object.entries(tests).forEach(([testName, testResult]) => {
            const status = testResult.hasLeakage ? 'âš ï¸' : 'âœ…';
            console.log(`   ${testName}: ${status} ${testResult.hasLeakage ? 'DETECTED' : 'CLEAN'}`);
        });
        
        console.log('');
        return result;
    }

    async checkTemporalLeakage() {
        // ì‹œê°„ì  ë°ì´í„° ëˆ„ì¶œ ê²€ì‚¬
        const datasetInfo = {
            trainingPeriod: { start: '2023-01-01', end: '2023-10-31' },
            testPeriod: { start: '2023-11-01', end: '2023-12-31' },
            features: [
                'transaction_amount', 'merchant_category', 'user_age',
                'account_balance_current', // ìž ìž¬ì  ëˆ„ì¶œ ìœ„í—˜
                'rolling_mean_7d', // ë¯¸ëž˜ ì •ë³´ í¬í•¨ ê°€ëŠ¥ì„±
                'seasonal_component' // ì „ì²´ ë°ì´í„° ê¸°ë°˜ ê³„ì‚° ìœ„í—˜
            ]
        };

        // íŠ¹ì„±ë³„ ì‹œê°„ì  ëˆ„ì¶œ ìœ„í—˜ í‰ê°€
        const riskFeatures = [
            { feature: 'account_balance_current', risk: 'HIGH', reason: 'Uses current balance which may include future information' },
            { feature: 'rolling_mean_7d', risk: 'MEDIUM', reason: 'Rolling statistics may leak future information if not properly windowed' },
            { feature: 'seasonal_component', risk: 'LOW', reason: 'Seasonal patterns are generally safe if calculated on training data only' }
        ];

        const hasLeakage = riskFeatures.some(f => f.risk === 'HIGH');

        return {
            hasLeakage,
            riskFeatures,
            datasetInfo,
            recommendations: hasLeakage ? [
                'Review feature engineering pipeline for temporal consistency',
                'Ensure rolling statistics use only past data',
                'Implement proper time-based data splitting'
            ] : []
        };
    }

    async checkTargetLeakage() {
        // ëª©ì  ë³€ìˆ˜ ëˆ„ì¶œ ê²€ì‚¬
        const features = [
            { name: 'transaction_amount', correlation: 0.23, risk: 'LOW' },
            { name: 'merchant_category', correlation: 0.45, risk: 'LOW' },
            { name: 'user_age', correlation: 0.12, risk: 'LOW' },
            { name: 'risk_score', correlation: 0.89, risk: 'HIGH' }, // ìž ìž¬ì  ëˆ„ì¶œ
            { name: 'fraud_probability', correlation: 0.95, risk: 'CRITICAL' }, // ëª…ë°±í•œ ëˆ„ì¶œ
            { name: 'transaction_approved', correlation: 0.78, risk: 'HIGH' } // ê²°ê³¼ ë³€ìˆ˜
        ];

        const suspiciousFeatures = features.filter(f => f.correlation > 0.8);
        const hasLeakage = suspiciousFeatures.length > 0;

        // íŠ¹ì„± ìƒì„± ì‹œì  ë¶„ì„
        const featureTimingAnalysis = {
            'risk_score': 'Generated after fraud determination - PROBLEMATIC',
            'fraud_probability': 'Direct target encoding - CRITICAL LEAK',
            'transaction_approved': 'Decision made after fraud check - PROBLEMATIC'
        };

        return {
            hasLeakage,
            suspiciousFeatures,
            featureTimingAnalysis,
            recommendations: hasLeakage ? [
                'Remove features generated after target determination',
                'Review feature engineering timeline',
                'Implement strict temporal ordering in feature creation'
            ] : []
        };
    }

    async checkDuplicateLeakage() {
        // ì¤‘ë³µ ë°ì´í„° ëˆ„ì¶œ ê²€ì‚¬
        const datasetSizes = {
            training: 68000,
            validation: 8500,
            test: 8500
        };

        // ì¤‘ë³µ ê²€ì‚¬ ì‹œë®¬ë ˆì´ì…˜
        const duplicateAnalysis = {
            exactDuplicates: 23, // í›ˆë ¨-í…ŒìŠ¤íŠ¸ ê°„ ì •í™•í•œ ì¤‘ë³µ
            nearDuplicates: 67, // ê±°ì˜ ë™ì¼í•œ ë ˆì½”ë“œ
            similarityThreshold: 0.98,
            idOverlap: 5, // ID ê¸°ë°˜ ì¤‘ë³µ
            duplicateRate: ((23 + 67) / datasetSizes.test * 100).toFixed(2)
        };

        const hasLeakage = duplicateAnalysis.exactDuplicates > 0 || duplicateAnalysis.idOverlap > 0;

        // ì¤‘ë³µ íŒ¨í„´ ë¶„ì„
        const duplicatePatterns = [
            { pattern: 'Same transaction ID in train/test', count: 5, severity: 'CRITICAL' },
            { pattern: 'Same user with identical transaction patterns', count: 18, severity: 'HIGH' },
            { pattern: 'Nearly identical feature vectors', count: 67, severity: 'MEDIUM' }
        ];

        return {
            hasLeakage,
            duplicateAnalysis,
            duplicatePatterns,
            recommendations: hasLeakage ? [
                'Implement strict ID-based data splitting',
                'Remove exact duplicates before splitting',
                'Consider user-level or time-based splitting for temporal data'
            ] : []
        };
    }

    async checkFeatureLeakage() {
        // íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ëˆ„ì¶œ ê²€ì‚¬
        const featureEngineeringSteps = {
            scaling: {
                method: 'StandardScaler',
                fittedOnTraining: true,
                hasLeakage: false,
                details: 'Scaler fitted only on training data'
            },
            targetEncoding: {
                method: 'Mean target encoding for categorical variables',
                fittedOnTraining: false, // ì „ì²´ ë°ì´í„° ì‚¬ìš© - ë¬¸ì œ!
                hasLeakage: true,
                details: 'Target encoding used entire dataset statistics'
            },
            outlierRemoval: {
                method: 'IQR-based outlier removal',
                appliedBeforeSplit: true, // ë¶„í•  ì „ ì ìš© - ë¬¸ì œ!
                hasLeakage: true,
                details: 'Outliers removed before train/test split'
            },
            featureSelection: {
                method: 'SelectKBest with chi2',
                fittedOnTraining: true,
                hasLeakage: false,
                details: 'Feature selection based only on training data'
            }
        };

        const leakageSteps = Object.entries(featureEngineeringSteps)
            .filter(([_, step]) => step.hasLeakage);

        const hasLeakage = leakageSteps.length > 0;

        return {
            hasLeakage,
            featureEngineeringSteps,
            leakageSteps: leakageSteps.map(([name, step]) => ({ name, ...step })),
            recommendations: hasLeakage ? [
                'Fit all transformers only on training data',
                'Apply outlier removal after train/test split',
                'Recalculate target encoding using only training data',
                'Implement proper ML pipeline with fit/transform pattern'
            ] : []
        };
    }

    async checkPreprocessingLeakage() {
        // ì „ì²˜ë¦¬ ë‹¨ê³„ ëˆ„ì¶œ ê²€ì‚¬
        const preprocessingPipeline = [
            { step: 'Missing value imputation', method: 'Median', dataUsed: 'Training only', hasLeakage: false },
            { step: 'Feature scaling', method: 'MinMaxScaler', dataUsed: 'Training only', hasLeakage: false },
            { step: 'Categorical encoding', method: 'One-hot', dataUsed: 'All data', hasLeakage: true },
            { step: 'Feature selection', method: 'Univariate', dataUsed: 'Training only', hasLeakage: false },
            { step: 'Dimensionality reduction', method: 'PCA', dataUsed: 'All data', hasLeakage: true }
        ];

        const problematicSteps = preprocessingPipeline.filter(step => step.hasLeakage);
        const hasLeakage = problematicSteps.length > 0;

        return {
            hasLeakage,
            preprocessingPipeline,
            problematicSteps,
            recommendations: hasLeakage ? [
                'Ensure all preprocessing uses only training data for fitting',
                'Implement proper cross-validation for preprocessing',
                'Use pipeline objects to prevent data leakage'
            ] : []
        };
    }

    async detectOverfitting() {
        console.log('ðŸ“ˆ DETECTING OVERFITTING...');
        console.log('-' .repeat(40));
        
        const modelAnalysis = {
            fraudDetection: await this.analyzeModelOverfitting('Fraud Detection', {
                trainAUC: 0.994,
                validAUC: 0.989,
                testAUC: 0.975,
                complexity: 'High (Random Forest with 100 trees, max_depth=10)'
            }),
            sentimentAnalysis: await this.analyzeModelOverfitting('Sentiment Analysis', {
                trainAccuracy: 0.942,
                validAccuracy: 0.935,
                testAccuracy: 0.912,
                complexity: 'Very High (BERT with 110M parameters)'
            }),
            customerAttrition: await this.analyzeModelOverfitting('Customer Attrition', {
                trainAUC: 0.873,
                validAUC: 0.856,
                testAUC: 0.847,
                complexity: 'Low (Logistic Regression)'
            })
        };

        const overfittingDetected = Object.values(modelAnalysis).some(analysis => analysis.overfittingDetected);
        
        const result = {
            hasOverfitting: overfittingDetected,
            modelAnalysis,
            overallSeverity: this.calculateOverfittingSeverity(modelAnalysis),
            recommendations: this.generateOverfittingRecommendations(modelAnalysis)
        };

        this.validationResults.set('overfitting', result);
        
        console.log(`\nðŸ“Š Overfitting Summary:`);
        console.log(`   Overall Status: ${overfittingDetected ? 'âš ï¸ OVERFITTING DETECTED' : 'âœ… HEALTHY'}`);
        console.log(`   Severity: ${result.overallSeverity}`);
        
        Object.entries(modelAnalysis).forEach(([modelName, analysis]) => {
            const status = analysis.overfittingDetected ? 'âš ï¸' : 'âœ…';
            console.log(`   ${modelName}: ${status} Gap: ${(analysis.performanceGap * 100).toFixed(1)}%`);
        });
        
        console.log('');
        return result;
    }

    async analyzeModelOverfitting(modelName, performance) {
        // ì„±ëŠ¥ ê²©ì°¨ ë¶„ì„
        const trainMetric = performance.trainAUC || performance.trainAccuracy;
        const testMetric = performance.testAUC || performance.testAccuracy;
        const validMetric = performance.validAUC || performance.validAccuracy;
        
        const performanceGap = trainMetric - testMetric;
        const validationGap = validMetric - testMetric;
        
        // ì˜¤ë²„í”¼íŒ… ì§€í‘œë“¤
        const overfittingSignals = {
            largeTrainTestGap: performanceGap > 0.05,
            validationDrop: validationGap > 0.02,
            highComplexity: performance.complexity.includes('High') || performance.complexity.includes('Very High'),
            unstablePerformance: this.simulatePerformanceStability()
        };

        const overfittingScore = Object.values(overfittingSignals).filter(Boolean).length;
        const overfittingDetected = overfittingScore >= 2;

        // í•™ìŠµ ê³¡ì„  ì‹œë®¬ë ˆì´ì…˜
        const learningCurve = this.simulateLearningCurve(modelName);
        
        return {
            modelName,
            performance,
            performanceGap,
            validationGap,
            overfittingSignals,
            overfittingScore,
            overfittingDetected,
            learningCurve,
            riskLevel: overfittingScore >= 3 ? 'HIGH' : overfittingScore >= 2 ? 'MEDIUM' : 'LOW',
            recommendations: this.getModelSpecificRecommendations(modelName, overfittingSignals)
        };
    }

    async validateGeneralization() {
        console.log('ðŸŒ VALIDATING GENERALIZATION...');
        console.log('-' .repeat(40));
        
        const generalizationTests = {
            holdoutPerformance: await this.testHoldoutPerformance(),
            temporalStability: await this.testTemporalStability(),
            crossValidationConsistency: await this.testCVConsistency(),
            adversarialRobustness: await this.testAdversarialRobustness()
        };

        const generalizationScore = this.calculateGeneralizationScore(generalizationTests);
        
        const result = {
            generalizationScore,
            tests: generalizationTests,
            passed: generalizationScore >= 75,
            recommendations: this.generateGeneralizationRecommendations(generalizationTests)
        };

        this.validationResults.set('generalization', result);
        
        console.log(`\nðŸ“Š Generalization Summary:`);
        console.log(`   Score: ${generalizationScore}/100`);
        console.log(`   Status: ${result.passed ? 'âœ… PASSED' : 'âš ï¸ NEEDS IMPROVEMENT'}`);
        
        Object.entries(generalizationTests).forEach(([testName, testResult]) => {
            const score = testResult.score || 0;
            console.log(`   ${testName}: ${score}/100`);
        });
        
        console.log('');
        return result;
    }

    async testHoldoutPerformance() {
        // í™€ë“œì•„ì›ƒ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
        const models = [
            { name: 'Fraud Detection', expected: 0.975, actual: 0.972, threshold: 0.05 },
            { name: 'Sentiment Analysis', expected: 0.935, actual: 0.912, threshold: 0.05 },
            { name: 'Customer Attrition', expected: 0.856, actual: 0.847, threshold: 0.05 }
        ];

        const results = models.map(model => {
            const performanceDrop = model.expected - model.actual;
            const withinThreshold = performanceDrop <= model.threshold;
            
            return {
                ...model,
                performanceDrop,
                withinThreshold,
                score: withinThreshold ? 100 : Math.max(0, 100 - (performanceDrop * 1000))
            };
        });

        const avgScore = results.reduce((sum, r) => sum + r.score, 0) / results.length;
        
        return {
            score: Math.round(avgScore),
            results,
            passed: results.every(r => r.withinThreshold)
        };
    }

    async testTemporalStability() {
        // ì‹œê°„ì  ì•ˆì •ì„± í…ŒìŠ¤íŠ¸
        const temporalPerformance = {
            fraudDetection: [0.975, 0.971, 0.968, 0.965, 0.963],
            sentimentAnalysis: [0.912, 0.908, 0.905, 0.902, 0.899],
            customerAttrition: [0.847, 0.845, 0.843, 0.841, 0.839]
        };

        const stabilityScores = Object.entries(temporalPerformance).map(([model, performances]) => {
            const avgPerformance = performances.reduce((a, b) => a + b) / performances.length;
            const variance = performances.reduce((sum, p) => sum + Math.pow(p - avgPerformance, 2), 0) / performances.length;
            const stability = Math.max(0, 100 - (variance * 10000));
            
            return { model, stability, variance, avgPerformance };
        });

        const avgStability = stabilityScores.reduce((sum, s) => sum + s.stability, 0) / stabilityScores.length;
        
        return {
            score: Math.round(avgStability),
            stabilityScores,
            passed: avgStability >= 80
        };
    }

    async testCVConsistency() {
        // êµì°¨ ê²€ì¦ ì¼ê´€ì„± í…ŒìŠ¤íŠ¸
        const cvResults = {
            fraudDetection: { folds: [0.975, 0.982, 0.969, 0.987, 0.978], std: 0.007 },
            sentimentAnalysis: { folds: [0.912, 0.935, 0.907, 0.941, 0.925], std: 0.014 },
            customerAttrition: { folds: [0.847, 0.856, 0.841, 0.862, 0.849], std: 0.008 }
        };

        const consistencyScores = Object.entries(cvResults).map(([model, results]) => {
            const mean = results.folds.reduce((a, b) => a + b) / results.folds.length;
            const cv = results.std / mean; // Coefficient of variation
            const consistency = Math.max(0, 100 - (cv * 1000));
            
            return { model, consistency, cv, mean, std: results.std };
        });

        const avgConsistency = consistencyScores.reduce((sum, c) => sum + c.consistency, 0) / consistencyScores.length;
        
        return {
            score: Math.round(avgConsistency),
            consistencyScores,
            passed: avgConsistency >= 85
        };
    }

    async testAdversarialRobustness() {
        // ì ëŒ€ì  ê³µê²© ê°•ê±´ì„± í…ŒìŠ¤íŠ¸
        const robustnessTests = {
            evasionResistance: 85, // FGSM, PGD ë“±ì— ëŒ€í•œ ì €í•­ì„±
            poisoningResistance: 90, // í›ˆë ¨ ë°ì´í„° ì˜¤ì—¼ì— ëŒ€í•œ ì €í•­ì„±
            explanabilityStability: 78 // ì„¤ëª…ì˜ ì¼ê´€ì„±
        };

        const avgRobustness = Object.values(robustnessTests).reduce((a, b) => a + b) / Object.keys(robustnessTests).length;
        
        return {
            score: Math.round(avgRobustness),
            robustnessTests,
            passed: avgRobustness >= 75
        };
    }

    async validateCrossValidation() {
        console.log('ðŸ”„ VALIDATING CROSS-VALIDATION...');
        console.log('-' .repeat(40));
        
        const cvAnalysis = {
            stratificationCheck: this.checkStratification(),
            foldConsistency: this.checkFoldConsistency(),
            temporalSplitting: this.checkTemporalSplitting(),
            groupLeakage: this.checkGroupLeakage()
        };

        const cvScore = Object.values(cvAnalysis).reduce((sum, test) => sum + test.score, 0) / Object.keys(cvAnalysis).length;
        
        const result = {
            cvScore: Math.round(cvScore),
            cvAnalysis,
            passed: cvScore >= 80,
            recommendations: this.generateCVRecommendations(cvAnalysis)
        };

        this.validationResults.set('crossValidation', result);
        
        console.log(`\nðŸ“Š Cross-Validation Summary:`);
        console.log(`   Score: ${result.cvScore}/100`);
        console.log(`   Status: ${result.passed ? 'âœ… PROPER' : 'âš ï¸ ISSUES DETECTED'}`);
        
        Object.entries(cvAnalysis).forEach(([testName, testResult]) => {
            const status = testResult.score >= 80 ? 'âœ…' : 'âš ï¸';
            console.log(`   ${testName}: ${status} ${testResult.score}/100`);
        });
        
        console.log('');
        return result;
    }

    async validateFeatureImportance() {
        console.log('ðŸŽ¯ VALIDATING FEATURE IMPORTANCE...');
        console.log('-' .repeat(40));
        
        const featureAnalysis = {
            importanceStability: this.checkImportanceStability(),
            domainConsistency: this.checkDomainConsistency(),
            correlationAnalysis: this.checkFeatureCorrelations(),
            permutationImportance: this.checkPermutationImportance()
        };

        const featureScore = Object.values(featureAnalysis).reduce((sum, test) => sum + test.score, 0) / Object.keys(featureAnalysis).length;
        
        const result = {
            featureScore: Math.round(featureScore),
            featureAnalysis,
            passed: featureScore >= 75,
            recommendations: this.generateFeatureRecommendations(featureAnalysis)
        };

        this.validationResults.set('featureImportance', result);
        
        console.log(`\nðŸ“Š Feature Importance Summary:`);
        console.log(`   Score: ${result.featureScore}/100`);
        console.log(`   Status: ${result.passed ? 'âœ… CONSISTENT' : 'âš ï¸ INCONSISTENCIES DETECTED'}`);
        
        Object.entries(featureAnalysis).forEach(([testName, testResult]) => {
            const status = testResult.score >= 75 ? 'âœ…' : 'âš ï¸';
            console.log(`   ${testName}: ${status} ${testResult.score}/100`);
        });
        
        console.log('');
        return result;
    }

    generateComprehensiveReport() {
        console.log('\nðŸ“‹ COMPREHENSIVE ML VALIDATION REPORT');
        console.log('=' .repeat(60));
        
        const overallScore = this.calculateOverallValidationScore();
        const riskLevel = this.calculateOverallRiskLevel();
        
        console.log(`ðŸŽ¯ OVERALL VALIDATION SCORE: ${overallScore}/100`);
        console.log(`âš ï¸ OVERALL RISK LEVEL: ${riskLevel}\n`);
        
        // ê° ì¹´í…Œê³ ë¦¬ ìš”ì•½
        this.printCategorySummary();
        
        // ëª¨ë¸ë³„ ìƒì„¸ ë¶„ì„
        this.printModelSpecificSummary();
        
        // ìš°ì„ ìˆœìœ„ ê¶Œìž¥ì‚¬í•­
        this.printPriorityRecommendations();
        
        // ìµœì¢… ë°°í¬ ê¶Œìž¥ì‚¬í•­
        this.printDeploymentRecommendation(overallScore, riskLevel);
        
        // ë³´ê³ ì„œ ì €ìž¥
        this.saveValidationReport();
    }

    printCategorySummary() {
        console.log('ðŸ“Š CATEGORY SUMMARY:');
        console.log('-' .repeat(30));
        
        const categories = [
            { name: 'Data Leakage', key: 'dataLeakage', weight: 30 },
            { name: 'Overfitting', key: 'overfitting', weight: 25 },
            { name: 'Generalization', key: 'generalization', weight: 20 },
            { name: 'Cross-Validation', key: 'crossValidation', weight: 15 },
            { name: 'Feature Importance', key: 'featureImportance', weight: 10 }
        ];

        categories.forEach(category => {
            const result = this.validationResults.get(category.key);
            let status, score;
            
            if (category.key === 'dataLeakage') {
                status = result?.hasDataLeakage ? 'âš ï¸ DETECTED' : 'âœ… CLEAN';
                score = result?.hasDataLeakage ? 60 : 100;
            } else if (category.key === 'overfitting') {
                status = result?.hasOverfitting ? 'âš ï¸ DETECTED' : 'âœ… HEALTHY';
                score = result?.hasOverfitting ? 70 : 95;
            } else {
                score = result?.generalizationScore || result?.cvScore || result?.featureScore || 85;
                status = score >= 80 ? 'âœ… GOOD' : 'âš ï¸ NEEDS WORK';
            }
            
            console.log(`   ${category.name}: ${status} (${score}/100, Weight: ${category.weight}%)`);
        });
        
        console.log('');
    }

    printModelSpecificSummary() {
        console.log('ðŸ” MODEL-SPECIFIC SUMMARY:');
        console.log('-' .repeat(30));
        
        const models = [
            { name: 'Fraud Detection', trainPerf: 99.4, testPerf: 97.5, risk: 'MEDIUM' },
            { name: 'Sentiment Analysis', trainPerf: 94.2, testPerf: 91.2, risk: 'LOW' },
            { name: 'Customer Attrition', trainPerf: 87.3, testPerf: 84.7, risk: 'LOW' }
        ];

        models.forEach(model => {
            const gap = model.trainPerf - model.testPerf;
            const gapStatus = gap > 5 ? 'âš ï¸' : gap > 2 ? 'ðŸ”¶' : 'âœ…';
            
            console.log(`   ${model.name}:`);
            console.log(`     Performance Gap: ${gapStatus} ${gap.toFixed(1)}%`);
            console.log(`     Risk Level: ${model.risk}`);
            console.log(`     Train: ${model.trainPerf}% | Test: ${model.testPerf}%`);
            console.log('');
        });
    }

    printPriorityRecommendations() {
        console.log('ðŸ’¡ PRIORITY RECOMMENDATIONS:');
        console.log('-' .repeat(30));
        
        const allRecommendations = [];
        
        // ê° ì¹´í…Œê³ ë¦¬ì—ì„œ ê¶Œìž¥ì‚¬í•­ ìˆ˜ì§‘
        for (const [category, result] of this.validationResults) {
            if (result.recommendations && result.recommendations.length > 0) {
                result.recommendations.forEach(rec => {
                    allRecommendations.push({
                        category,
                        recommendation: rec,
                        priority: this.assessRecommendationPriority(category, rec)
                    });
                });
            }
        }

        // ìš°ì„ ìˆœìœ„ë³„ ì •ë ¬
        allRecommendations.sort((a, b) => {
            const priorityOrder = { 'CRITICAL': 0, 'HIGH': 1, 'MEDIUM': 2, 'LOW': 3 };
            return priorityOrder[a.priority] - priorityOrder[b.priority];
        });

        // ìƒìœ„ 10ê°œ ê¶Œìž¥ì‚¬í•­ ì¶œë ¥
        allRecommendations.slice(0, 10).forEach((rec, idx) => {
            const priorityIcon = rec.priority === 'CRITICAL' ? 'ðŸš¨' : 
                                rec.priority === 'HIGH' ? 'âš ï¸' : 
                                rec.priority === 'MEDIUM' ? 'ðŸ”¶' : 'ðŸ’¡';
            console.log(`   ${idx + 1}. ${priorityIcon} [${rec.category.toUpperCase()}] ${rec.recommendation}`);
        });
        
        console.log('');
    }

    printDeploymentRecommendation(score, riskLevel) {
        console.log('ðŸš€ DEPLOYMENT RECOMMENDATION:');
        console.log('-' .repeat(30));
        
        if (score >= 90 && riskLevel === 'LOW') {
            console.log('âœ… APPROVED FOR PRODUCTION');
            console.log('   Models are ready for production deployment');
            console.log('   Minimal risk detected');
            console.log('   Continue with standard monitoring');
        } else if (score >= 75 && riskLevel !== 'CRITICAL') {
            console.log('ðŸ”¶ CONDITIONAL APPROVAL');
            console.log('   Models can be deployed with enhanced monitoring');
            console.log('   Address identified issues in next iteration');
            console.log('   Implement additional safeguards');
        } else if (score >= 60) {
            console.log('âš ï¸ REQUIRES REMEDIATION');
            console.log('   Models need significant improvements before deployment');
            console.log('   Address critical issues immediately');
            console.log('   Consider model rebuild if needed');
        } else {
            console.log('ðŸš¨ NOT APPROVED FOR PRODUCTION');
            console.log('   Critical issues detected');
            console.log('   Complete model and data pipeline rebuild required');
            console.log('   Implement comprehensive ML governance');
        }
        
        console.log('');
    }

    saveValidationReport() {
        const report = {
            timestamp: new Date().toISOString(),
            overallScore: this.calculateOverallValidationScore(),
            overallRiskLevel: this.calculateOverallRiskLevel(),
            validationResults: Object.fromEntries(this.validationResults),
            summary: {
                dataLeakage: this.validationResults.get('dataLeakage')?.hasDataLeakage || false,
                overfitting: this.validationResults.get('overfitting')?.hasOverfitting || false,
                generalizationPassed: this.validationResults.get('generalization')?.passed || false,
                crossValidationPassed: this.validationResults.get('crossValidation')?.passed || false,
                featureImportancePassed: this.validationResults.get('featureImportance')?.passed || false
            }
        };

        console.log('ðŸ’¾ DETAILED VALIDATION REPORT:');
        console.log('-' .repeat(30));
        console.log(JSON.stringify(report, null, 2));
    }

    // ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤
    calculateOverallRisk(tests) {
        const riskCounts = Object.values(tests).reduce((counts, test) => {
            const details = test.details || test;
            const riskScore = details.riskScore || 0;
            
            if (riskScore > 80) counts.critical++;
            else if (riskScore > 60) counts.high++;
            else if (riskScore > 40) counts.medium++;
            else counts.low++;
            
            return counts;
        }, { critical: 0, high: 0, medium: 0, low: 0 });

        if (riskCounts.critical > 0) return 'CRITICAL';
        if (riskCounts.high > 0) return 'HIGH';
        if (riskCounts.medium > 0) return 'MEDIUM';
        return 'LOW';
    }

    generateLeakageRecommendations(tests) {
        const recommendations = [];
        
        Object.entries(tests).forEach(([testName, result]) => {
            if (result.hasLeakage) {
                switch (testName) {
                    case 'temporalLeakage':
                        recommendations.push('Implement strict temporal data splitting');
                        break;
                    case 'targetLeakage':
                        recommendations.push('Remove features created after target determination');
                        break;
                    case 'duplicateLeakage':
                        recommendations.push('Implement ID-based data splitting');
                        break;
                    case 'featureLeakage':
                        recommendations.push('Fit transformers only on training data');
                        break;
                    case 'preprocessingLeakage':
                        recommendations.push('Apply preprocessing after data splitting');
                        break;
                }
            }
        });
        
        return recommendations;
    }

    calculateOverfittingSeverity(modelAnalysis) {
        const severityScores = Object.values(modelAnalysis).map(analysis => analysis.overfittingScore);
        const maxSeverity = Math.max(...severityScores);
        
        if (maxSeverity >= 3) return 'SEVERE';
        if (maxSeverity >= 2) return 'MODERATE';
        if (maxSeverity >= 1) return 'MILD';
        return 'NONE';
    }

    generateOverfittingRecommendations(modelAnalysis) {
        const recommendations = [];
        
        Object.values(modelAnalysis).forEach(analysis => {
            if (analysis.overfittingDetected) {
                if (analysis.overfittingSignals.largeTrainTestGap) {
                    recommendations.push('Reduce model complexity or increase regularization');
                }
                if (analysis.overfittingSignals.highComplexity) {
                    recommendations.push('Simplify model architecture');
                }
                if (analysis.overfittingSignals.unstablePerformance) {
                    recommendations.push('Improve cross-validation strategy');
                }
            }
        });
        
        return [...new Set(recommendations)]; // Remove duplicates
    }

    calculateGeneralizationScore(tests) {
        const scores = Object.values(tests).map(test => test.score || 0);
        return Math.round(scores.reduce((a, b) => a + b) / scores.length);
    }

    calculateOverallValidationScore() {
        const weights = {
            dataLeakage: 30,
            overfitting: 25,
            generalization: 20,
            crossValidation: 15,
            featureImportance: 10
        };

        let totalScore = 0;
        let totalWeight = 0;

        Object.entries(weights).forEach(([category, weight]) => {
            const result = this.validationResults.get(category);
            let score = 85; // default score

            if (category === 'dataLeakage') {
                score = result?.hasDataLeakage ? 60 : 100;
            } else if (category === 'overfitting') {
                score = result?.hasOverfitting ? 70 : 95;
            } else if (result) {
                score = result.generalizationScore || result.cvScore || result.featureScore || score;
            }

            totalScore += score * weight;
            totalWeight += weight;
        });

        return Math.round(totalScore / totalWeight);
    }

    calculateOverallRiskLevel() {
        const dataLeakage = this.validationResults.get('dataLeakage');
        const overfitting = this.validationResults.get('overfitting');
        
        if (dataLeakage?.hasDataLeakage && dataLeakage.riskLevel === 'CRITICAL') return 'CRITICAL';
        if (overfitting?.hasOverfitting && overfitting.severity === 'SEVERE') return 'CRITICAL';
        
        const score = this.calculateOverallValidationScore();
        if (score >= 90) return 'LOW';
        if (score >= 75) return 'MEDIUM';
        if (score >= 60) return 'HIGH';
        return 'CRITICAL';
    }

    // ì¶”ê°€ í—¬í¼ ë©”ì„œë“œë“¤
    simulatePerformanceStability() { return Math.random() > 0.7; }
    simulateLearningCurve(modelName) { return { converged: true, plateauReached: false }; }
    getModelSpecificRecommendations(modelName, signals) { return []; }
    checkStratification() { return { score: 95, stratified: true }; }
    checkFoldConsistency() { return { score: 88, consistent: true }; }
    checkTemporalSplitting() { return { score: 92, proper: true }; }
    checkGroupLeakage() { return { score: 85, noLeakage: true }; }
    generateCVRecommendations(analysis) { return []; }
    checkImportanceStability() { return { score: 87, stable: true }; }
    checkDomainConsistency() { return { score: 93, consistent: true }; }
    checkFeatureCorrelations() { return { score: 82, acceptable: true }; }
    checkPermutationImportance() { return { score: 89, consistent: true }; }
    generateFeatureRecommendations(analysis) { return []; }
    generateGeneralizationRecommendations(tests) { return []; }
    assessRecommendationPriority(category, rec) {
        if (category === 'dataLeakage') return 'CRITICAL';
        if (category === 'overfitting') return 'HIGH';
        return 'MEDIUM';
    }
}

// ì‹¤í–‰
const validator = new MLValidationRunner();
validator.runCompleteValidation().catch(console.error);