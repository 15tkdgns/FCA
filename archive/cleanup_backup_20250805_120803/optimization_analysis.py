#!/usr/bin/env python3
"""
FCA í”„ë¡œì íŠ¸ ìµœì í™” ë° ì ê²€ ë„êµ¬
=====================================

í”„ë¡œì íŠ¸ ìƒíƒœë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  ìµœì í™” ê¶Œì¥ì‚¬í•­ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import os
import sys
import json
import subprocess
import time
from pathlib import Path
from collections import defaultdict, Counter
import re

class FCAOptimizationAnalyzer:
    def __init__(self, project_root="/root/FCA"):
        self.project_root = Path(project_root)
        self.analysis_results = {}
        
    def analyze_project_structure(self):
        """í”„ë¡œì íŠ¸ êµ¬ì¡° ë¶„ì„"""
        print("ğŸ—ï¸  í”„ë¡œì íŠ¸ êµ¬ì¡° ë¶„ì„ ì¤‘...")
        
        structure = {
            'python_files': 0,
            'javascript_files': 0,
            'config_files': 0,
            'data_files': 0,
            'documentation': 0,
            'total_size_mb': 0,
            'directories': {},
            'large_files': []
        }
        
        for root, dirs, files in os.walk(self.project_root):
            rel_path = os.path.relpath(root, self.project_root)
            if rel_path == '.':
                rel_path = 'root'
                
            structure['directories'][rel_path] = len(files)
            
            for file in files:
                file_path = Path(root) / file
                file_size = file_path.stat().st_size / (1024 * 1024)  # MB
                
                # ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²´í¬ (50MB ì´ìƒ)
                if file_size > 50:
                    structure['large_files'].append({
                        'path': str(file_path.relative_to(self.project_root)),
                        'size_mb': round(file_size, 2)
                    })
                
                # íŒŒì¼ íƒ€ì…ë³„ ì¹´ìš´íŠ¸
                if file.endswith('.py'):
                    structure['python_files'] += 1
                elif file.endswith('.js'):
                    structure['javascript_files'] += 1
                elif file.endswith(('.json', '.yaml', '.yml', '.toml', '.ini')):
                    structure['config_files'] += 1
                elif file.endswith(('.csv', '.parquet', '.pkl')):
                    structure['data_files'] += 1
                elif file.endswith(('.md', '.rst', '.txt')):
                    structure['documentation'] += 1
                    
                structure['total_size_mb'] += file_size
        
        structure['total_size_mb'] = round(structure['total_size_mb'], 2)
        self.analysis_results['structure'] = structure
        return structure
    
    def analyze_performance_bottlenecks(self):
        """ì„±ëŠ¥ ë³‘ëª© ì§€ì  ë¶„ì„"""
        print("âš¡ ì„±ëŠ¥ ë³‘ëª© ì§€ì  ë¶„ì„ ì¤‘...")
        
        bottlenecks = {
            'large_data_files': [],
            'duplicate_dependencies': [],
            'inefficient_patterns': [],
            'memory_intensive_operations': [],
            'recommendations': []
        }
        
        # ëŒ€ìš©ëŸ‰ ë°ì´í„° íŒŒì¼ ê²€ì‚¬
        for root, dirs, files in os.walk(self.project_root / 'data'):
            for file in files:
                file_path = Path(root) / file
                if file_path.exists():
                    size_mb = file_path.stat().st_size / (1024 * 1024)
                    if size_mb > 100:  # 100MB ì´ìƒ
                        bottlenecks['large_data_files'].append({
                            'file': str(file_path.relative_to(self.project_root)),
                            'size_mb': round(size_mb, 2)
                        })
        
        # Python ì½”ë“œ íŒ¨í„´ ë¶„ì„
        python_files = list(self.project_root.rglob("*.py"))
        for py_file in python_files[:20]:  # ì²« 20ê°œ íŒŒì¼ë§Œ ìƒ˜í”Œë§
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    
                # ë¹„íš¨ìœ¨ì  íŒ¨í„´ ê²€ì‚¬
                if 'for' in content and 'append' in content:
                    if content.count('append') > 10:
                        bottlenecks['inefficient_patterns'].append({
                            'file': str(py_file.relative_to(self.project_root)),
                            'issue': 'Multiple append operations in loops'
                        })
                        
                if 'pd.read_csv' in content and 'pd.concat' in content:
                    bottlenecks['memory_intensive_operations'].append({
                        'file': str(py_file.relative_to(self.project_root)),
                        'issue': 'Large DataFrame operations detected'
                    })
            except:
                continue
        
        # ê¶Œì¥ì‚¬í•­ ìƒì„±
        if bottlenecks['large_data_files']:
            bottlenecks['recommendations'].append("ëŒ€ìš©ëŸ‰ ë°ì´í„° íŒŒì¼ì€ ì••ì¶•í•˜ê±°ë‚˜ ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•˜ì„¸ìš”")
        if bottlenecks['inefficient_patterns']:
            bottlenecks['recommendations'].append("ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜ì´ë‚˜ ë²¡í„°í™” ì—°ì‚°ì„ ì‚¬ìš©í•˜ì„¸ìš”")
        if bottlenecks['memory_intensive_operations']:
            bottlenecks['recommendations'].append("ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬ë‚˜ Daskë¥¼ ê³ ë ¤í•´ë³´ì„¸ìš”")
            
        self.analysis_results['performance'] = bottlenecks
        return bottlenecks
    
    def analyze_code_quality(self):
        """ì½”ë“œ í’ˆì§ˆ ë° ë³´ì•ˆ ì ê²€"""
        print("ğŸ” ì½”ë“œ í’ˆì§ˆ ë° ë³´ì•ˆ ì ê²€ ì¤‘...")
        
        quality = {
            'duplicated_code': [],
            'security_issues': [],
            'code_complexity': [],
            'documentation_coverage': 0,
            'test_coverage': 0,
            'recommendations': []
        }
        
        # ë¬¸ì„œí™” ì»¤ë²„ë¦¬ì§€ ì²´í¬
        python_files = list(self.project_root.rglob("*.py"))
        documented_files = 0
        
        for py_file in python_files[:50]:  # ìƒ˜í”Œë§
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    if '"""' in content or "'''" in content:
                        documented_files += 1
                        
                    # ë³´ì•ˆ ì´ìŠˆ ì²´í¬
                    security_patterns = [
                        (r'password\s*=\s*["\'][^"\']+["\']', 'Hardcoded password'),
                        (r'api_key\s*=\s*["\'][^"\']+["\']', 'Hardcoded API key'),
                        (r'eval\s*\(', 'Dangerous eval() usage'),
                        (r'exec\s*\(', 'Dangerous exec() usage'),
                        (r'subprocess\.call.*shell=True', 'Shell injection risk')
                    ]
                    
                    for pattern, issue in security_patterns:
                        if re.search(pattern, content, re.IGNORECASE):
                            quality['security_issues'].append({
                                'file': str(py_file.relative_to(self.project_root)),
                                'issue': issue
                            })
            except:
                continue
        
        quality['documentation_coverage'] = round(documented_files / len(python_files) * 100, 1) if python_files else 0
        
        # í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ì²´í¬
        test_files = list(self.project_root.rglob("test*.py")) + list(self.project_root.rglob("*test.py"))
        quality['test_coverage'] = round(len(test_files) / len(python_files) * 100, 1) if python_files else 0
        
        # ê¶Œì¥ì‚¬í•­
        if quality['documentation_coverage'] < 50:
            quality['recommendations'].append("ë¬¸ì„œí™” ì»¤ë²„ë¦¬ì§€ê°€ ë‚®ìŠµë‹ˆë‹¤. docstring ì¶”ê°€ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤")
        if quality['test_coverage'] < 30:
            quality['recommendations'].append("í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ê°€ ë‚®ìŠµë‹ˆë‹¤. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì¶”ê°€ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤")
        if quality['security_issues']:
            quality['recommendations'].append("ë³´ì•ˆ ì´ìŠˆê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ì¦‰ì‹œ ìˆ˜ì •í•˜ì„¸ìš”")
            
        self.analysis_results['quality'] = quality
        return quality
    
    def check_dependencies(self):
        """ì˜ì¡´ì„± ë¶„ì„"""
        print("ğŸ“¦ ì˜ì¡´ì„± ë¶„ì„ ì¤‘...")
        
        deps = {
            'python_packages': [],
            'javascript_packages': [],
            'outdated_packages': [],
            'security_vulnerabilities': [],
            'recommendations': []
        }
        
        # requirements.txt ì²´í¬
        req_file = self.project_root / 'requirements.txt'
        if req_file.exists():
            with open(req_file, 'r') as f:
                deps['python_packages'] = [line.strip() for line in f if line.strip() and not line.startswith('#')]
        
        # package.json ì²´í¬
        pkg_file = self.project_root / 'package.json'
        if pkg_file.exists():
            try:
                with open(pkg_file, 'r') as f:
                    pkg_data = json.load(f)
                    deps['javascript_packages'] = list(pkg_data.get('dependencies', {}).keys())
            except:
                pass
        
        self.analysis_results['dependencies'] = deps
        return deps
    
    def generate_optimization_recommendations(self):
        """ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        print("ğŸ’¡ ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„± ì¤‘...")
        
        recommendations = {
            'immediate_actions': [],
            'performance_improvements': [],
            'code_quality_improvements': [],
            'security_enhancements': [],
            'monitoring_setup': []
        }
        
        structure = self.analysis_results.get('structure', {})
        performance = self.analysis_results.get('performance', {})
        quality = self.analysis_results.get('quality', {})
        
        # ì¦‰ì‹œ ì¡°ì¹˜ í•„ìš”
        if structure.get('total_size_mb', 0) > 1000:
            recommendations['immediate_actions'].append("í”„ë¡œì íŠ¸ í¬ê¸°ê°€ 1GBë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤. ë¶ˆí•„ìš”í•œ íŒŒì¼ ì •ë¦¬ í•„ìš”")
        
        if quality.get('security_issues'):
            recommendations['immediate_actions'].append("ë³´ì•ˆ ì´ìŠˆê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ì¦‰ì‹œ ìˆ˜ì • í•„ìš”")
        
        # ì„±ëŠ¥ ê°œì„ 
        if performance.get('large_data_files'):
            recommendations['performance_improvements'].append("ëŒ€ìš©ëŸ‰ ë°ì´í„° íŒŒì¼ ì••ì¶• ë˜ëŠ” ì²­í¬ ì²˜ë¦¬ êµ¬í˜„")
        
        if performance.get('inefficient_patterns'):
            recommendations['performance_improvements'].append("ë¹„íš¨ìœ¨ì  ì½”ë“œ íŒ¨í„´ ë¦¬íŒ©í† ë§")
        
        # ì½”ë“œ í’ˆì§ˆ ê°œì„ 
        if quality.get('documentation_coverage', 0) < 50:
            recommendations['code_quality_improvements'].append("ë¬¸ì„œí™” ì»¤ë²„ë¦¬ì§€ í–¥ìƒ (í˜„ì¬: {}%)".format(quality.get('documentation_coverage', 0)))
        
        if quality.get('test_coverage', 0) < 30:
            recommendations['code_quality_improvements'].append("í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ í–¥ìƒ (í˜„ì¬: {}%)".format(quality.get('test_coverage', 0)))
        
        # ëª¨ë‹ˆí„°ë§ ì„¤ì •
        recommendations['monitoring_setup'].extend([
            "ë¡œê·¸ ë ˆë²¨ ë° ë¡œí…Œì´ì…˜ ì •ì±… ì„¤ì •",
            "ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œìŠ¤í…œ êµ¬ì¶•",
            "ì—ëŸ¬ ì¶”ì  ë° ì•Œë¦¼ ì‹œìŠ¤í…œ êµ¬ì¶•",
            "ëŒ€ì‹œë³´ë“œ í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€"
        ])
        
        self.analysis_results['recommendations'] = recommendations
        return recommendations
    
    def run_full_analysis(self):
        """ì „ì²´ ë¶„ì„ ì‹¤í–‰"""
        print("ğŸš€ FCA í”„ë¡œì íŠ¸ ìµœì í™” ë¶„ì„ ì‹œì‘")
        print("=" * 50)
        
        start_time = time.time()
        
        # ê° ë¶„ì„ ì‹¤í–‰
        self.analyze_project_structure()
        self.analyze_performance_bottlenecks()
        self.analyze_code_quality()
        self.check_dependencies()
        self.generate_optimization_recommendations()
        
        analysis_time = time.time() - start_time
        
        # ê²°ê³¼ ì¶œë ¥
        self.print_analysis_results()
        
        # JSON íŒŒì¼ë¡œ ì €ì¥
        output_file = self.project_root / 'optimization_analysis_results.json'
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(self.analysis_results, f, indent=2, ensure_ascii=False)
        
        print(f"\nâœ… ë¶„ì„ ì™„ë£Œ! (ì†Œìš”ì‹œê°„: {analysis_time:.2f}ì´ˆ)")
        print(f"ğŸ“ ìƒì„¸ ê²°ê³¼: {output_file}")
        
        return self.analysis_results
    
    def print_analysis_results(self):
        """ë¶„ì„ ê²°ê³¼ ì¶œë ¥"""
        print("\nğŸ“Š ë¶„ì„ ê²°ê³¼ ìš”ì•½")
        print("=" * 50)
        
        # í”„ë¡œì íŠ¸ êµ¬ì¡°
        structure = self.analysis_results.get('structure', {})
        print(f"ğŸ“ í”„ë¡œì íŠ¸ í¬ê¸°: {structure.get('total_size_mb', 0)}MB")
        print(f"ğŸ Python íŒŒì¼: {structure.get('python_files', 0)}ê°œ")
        print(f"ğŸ“œ JavaScript íŒŒì¼: {structure.get('javascript_files', 0)}ê°œ")
        print(f"ğŸ“Š ë°ì´í„° íŒŒì¼: {structure.get('data_files', 0)}ê°œ")
        
        # ì„±ëŠ¥
        performance = self.analysis_results.get('performance', {})
        print(f"\nâš¡ ì„±ëŠ¥ ì´ìŠˆ:")
        print(f"   ëŒ€ìš©ëŸ‰ íŒŒì¼: {len(performance.get('large_data_files', []))}ê°œ")
        print(f"   ë¹„íš¨ìœ¨ì  íŒ¨í„´: {len(performance.get('inefficient_patterns', []))}ê°œ")
        
        # ì½”ë“œ í’ˆì§ˆ
        quality = self.analysis_results.get('quality', {})
        print(f"\nğŸ” ì½”ë“œ í’ˆì§ˆ:")
        print(f"   ë¬¸ì„œí™” ì»¤ë²„ë¦¬ì§€: {quality.get('documentation_coverage', 0)}%")
        print(f"   í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€: {quality.get('test_coverage', 0)}%")
        print(f"   ë³´ì•ˆ ì´ìŠˆ: {len(quality.get('security_issues', []))}ê°œ")
        
        # ê¶Œì¥ì‚¬í•­
        recommendations = self.analysis_results.get('recommendations', {})
        print(f"\nğŸ’¡ ì£¼ìš” ê¶Œì¥ì‚¬í•­:")
        for action in recommendations.get('immediate_actions', [])[:3]:
            print(f"   ğŸš¨ {action}")
        for improvement in recommendations.get('performance_improvements', [])[:3]:
            print(f"   âš¡ {improvement}")

if __name__ == "__main__":
    analyzer = FCAOptimizationAnalyzer()
    analyzer.run_full_analysis()