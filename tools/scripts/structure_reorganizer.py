#!/usr/bin/env python3
"""
FCA í”„ë¡œì íŠ¸ êµ¬ì¡° ì¬ì •ë¦¬ ë„êµ¬
============================
í”„ë¡œì íŠ¸ êµ¬ì¡°ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ì¬ì •ë¦¬í•©ë‹ˆë‹¤.
"""

import os
import shutil
import json
from pathlib import Path
from datetime import datetime

class FCAStructureReorganizer:
    def __init__(self, project_root="/root/FCA"):
        self.project_root = Path(project_root)
        self.reorganize_log = []
        
        # í‘œì¤€ í”„ë¡œì íŠ¸ êµ¬ì¡° ì •ì˜
        self.target_structure = {
            'src/': {
                'description': 'í•µì‹¬ ì†ŒìŠ¤ ì½”ë“œ',
                'subdirs': ['fca/', 'static_dashboard/']
            },
            'data/': {
                'description': 'ë°ì´í„° íŒŒì¼ë“¤',
                'subdirs': ['raw/', 'processed/', 'models/']
            },
            'tests/': {
                'description': 'í…ŒìŠ¤íŠ¸ ì½”ë“œ',
                'subdirs': ['unit/', 'integration/', 'e2e/']
            },
            'docs/': {
                'description': 'ë¬¸ì„œ ë° ê°€ì´ë“œ',
                'subdirs': ['api/', 'guides/', 'reports/']
            },
            'tools/': {
                'description': 'ìœ í‹¸ë¦¬í‹° ë° ìŠ¤í¬ë¦½íŠ¸',
                'subdirs': ['scripts/', 'notebooks/', 'utilities/']
            },
            'config/': {
                'description': 'ì„¤ì • íŒŒì¼ë“¤',
                'subdirs': []
            },
            'archive/': {
                'description': 'ë°±ì—… ë° ì•„ì¹´ì´ë¸Œ',
                'subdirs': []
            },
            'logs/': {
                'description': 'ë¡œê·¸ íŒŒì¼ë“¤',
                'subdirs': []
            }
        }
        
        # íŒŒì¼ ë¶„ë¥˜ ê·œì¹™
        self.file_classification = {
            'config_files': ['.json', '.yml', '.yaml', '.toml', '.ini', '.env'],
            'documentation': ['.md', '.rst', '.txt'],
            'python_scripts': ['.py'],
            'javascript_files': ['.js'],
            'data_files': ['.csv', '.pkl', '.parquet', '.h5'],
            'notebook_files': ['.ipynb'],
            'image_files': ['.png', '.jpg', '.jpeg', '.gif', '.svg'],
            'archive_files': ['.zip', '.tar', '.gz', '.bz2']
        }
    
    def analyze_current_structure(self):
        """í˜„ì¬ êµ¬ì¡° ë¶„ì„"""
        print("ğŸ“Š í˜„ì¬ í”„ë¡œì íŠ¸ êµ¬ì¡° ë¶„ì„ ì¤‘...")
        
        current_structure = {}
        root_files = []
        
        # ë£¨íŠ¸ ë ˆë²¨ ë¶„ì„
        for item in self.project_root.iterdir():
            if item.is_dir() and not item.name.startswith('.'):
                file_count = len(list(item.rglob('*')))
                current_structure[item.name] = {
                    'type': 'directory',
                    'file_count': file_count,
                    'size_mb': self._get_dir_size(item)
                }
            elif item.is_file():
                root_files.append({
                    'name': item.name,
                    'size_mb': item.stat().st_size / (1024 * 1024),
                    'type': self._classify_file(item)
                })
        
        print(f"âœ… ë¶„ì„ ì™„ë£Œ: {len(current_structure)}ê°œ ë””ë ‰í† ë¦¬, {len(root_files)}ê°œ ë£¨íŠ¸ íŒŒì¼")
        return current_structure, root_files
    
    def _get_dir_size(self, dir_path):
        """ë””ë ‰í† ë¦¬ í¬ê¸° ê³„ì‚°"""
        try:
            total_size = sum(f.stat().st_size for f in dir_path.rglob('*') if f.is_file())
            return round(total_size / (1024 * 1024), 2)
        except (OSError, PermissionError):
            return 0
    
    def _classify_file(self, file_path):
        """íŒŒì¼ ë¶„ë¥˜"""
        suffix = file_path.suffix.lower()
        
        for file_type, extensions in self.file_classification.items():
            if suffix in extensions:
                return file_type
        
        return 'other'
    
    def create_target_directories(self):
        """ëª©í‘œ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±"""
        print("ğŸ“ í‘œì¤€ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„± ì¤‘...")
        
        created_dirs = []
        
        for main_dir, config in self.target_structure.items():
            main_path = self.project_root / main_dir
            
            if not main_path.exists():
                main_path.mkdir(exist_ok=True)
                created_dirs.append(main_dir)
                self.reorganize_log.append(f"ë””ë ‰í† ë¦¬ ìƒì„±: {main_dir}")
            
            # ì„œë¸Œ ë””ë ‰í† ë¦¬ ìƒì„±
            for subdir in config['subdirs']:
                sub_path = main_path / subdir
                if not sub_path.exists():
                    sub_path.mkdir(exist_ok=True)
                    created_dirs.append(f"{main_dir}{subdir}")
        
        print(f"âœ… ë””ë ‰í† ë¦¬ ìƒì„± ì™„ë£Œ: {len(created_dirs)}ê°œ")
        return created_dirs
    
    def reorganize_root_files(self):
        """ë£¨íŠ¸ ë ˆë²¨ íŒŒì¼ ì¬ì •ë¦¬"""
        print("ğŸ“„ ë£¨íŠ¸ ë ˆë²¨ íŒŒì¼ ì¬ì •ë¦¬ ì¤‘...")
        
        moved_files = []
        
        for item in self.project_root.iterdir():
            if item.is_file() and not item.name.startswith('.'):
                target_dir = self._determine_target_directory(item)
                
                if target_dir:
                    target_path = self.project_root / target_dir / item.name
                    
                    try:
                        # ì¤‘ë³µ íŒŒì¼ ì²´í¬
                        if target_path.exists():
                            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                            name_parts = item.name.rsplit('.', 1)
                            if len(name_parts) == 2:
                                new_name = f"{name_parts[0]}_{timestamp}.{name_parts[1]}"
                            else:
                                new_name = f"{item.name}_{timestamp}"
                            target_path = target_path.parent / new_name
                        
                        shutil.move(str(item), str(target_path))
                        moved_files.append({
                            'file': item.name,
                            'from': 'root',
                            'to': target_dir
                        })
                        self.reorganize_log.append(f"íŒŒì¼ ì´ë™: {item.name} â†’ {target_dir}")
                        
                    except (OSError, PermissionError, shutil.Error) as e:
                        print(f"âš ï¸ íŒŒì¼ ì´ë™ ì‹¤íŒ¨: {item.name} - {e}")
        
        print(f"âœ… ë£¨íŠ¸ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ: {len(moved_files)}ê°œ íŒŒì¼ ì´ë™")
        return moved_files
    
    def _determine_target_directory(self, file_path):
        """íŒŒì¼ì˜ ëª©í‘œ ë””ë ‰í† ë¦¬ ê²°ì •"""
        file_type = self._classify_file(file_path)
        file_name = file_path.name.lower()
        
        # íŠ¹ë³„í•œ íŒŒì¼ë“¤ ì²˜ë¦¬
        if file_name in ['readme.md', 'license', 'changelog.md', 'contributing.md']:
            return None  # ë£¨íŠ¸ì— ìœ ì§€
        
        if file_name.startswith('requirements'):
            return 'config/'
        
        if 'test' in file_name or file_name.startswith('test_'):
            return 'tests/'
        
        # íƒ€ì…ë³„ ë¶„ë¥˜
        if file_type == 'config_files':
            return 'config/'
        elif file_type == 'documentation':
            return 'docs/'
        elif file_type == 'python_scripts':
            if 'notebook' in file_name or 'analysis' in file_name:
                return 'tools/notebooks/'
            else:
                return 'tools/scripts/'
        elif file_type == 'notebook_files':
            return 'tools/notebooks/'
        elif file_type == 'data_files':
            return 'data/raw/'
        elif file_type == 'image_files':
            return 'docs/images/'
        elif file_type == 'archive_files':
            return 'archive/'
        
        # ê¸°ë³¸ì ìœ¼ë¡œ toolsë¡œ
        return 'tools/utilities/'
    
    def consolidate_similar_directories(self):
        """ìœ ì‚¬í•œ ë””ë ‰í† ë¦¬ í†µí•©"""
        print("ğŸ”„ ìœ ì‚¬í•œ ë””ë ‰í† ë¦¬ í†µí•© ì¤‘...")
        
        consolidations = [
            # ë°±ì—…/ì•„ì¹´ì´ë¸Œ ë””ë ‰í† ë¦¬ë“¤
            {
                'source_patterns': ['*backup*', '*archive*', 'deprecated'],
                'target': 'archive/',
                'exclude': ['archive/']  # ì´ë¯¸ ì •ë¦¬ëœ ê²ƒì€ ì œì™¸
            },
            # ë¬¸ì„œ ê´€ë ¨
            {
                'source_patterns': ['documentation', 'guides'],  
                'target': 'docs/',
                'exclude': ['docs/']
            },
            # ë„êµ¬ ê´€ë ¨
            {
                'source_patterns': ['scripts', 'utilities', 'notebooks'],
                'target': 'tools/',
                'exclude': ['tools/']
            }
        ]
        
        consolidated_count = 0
        
        for consolidation in consolidations:
            for pattern in consolidation['source_patterns']:
                for dir_path in self.project_root.glob(pattern):
                    if (dir_path.is_dir() and 
                        str(dir_path.relative_to(self.project_root)) not in consolidation['exclude']):
                        
                        target_dir = self.project_root / consolidation['target'] / dir_path.name
                        
                        try:
                            if target_dir.exists():
                                # ê¸°ì¡´ íƒ€ê²Ÿì´ ìˆìœ¼ë©´ ë‚´ìš©ë¬¼ì„ ì´ë™
                                for item in dir_path.iterdir():
                                    target_item = target_dir / item.name
                                    if not target_item.exists():
                                        shutil.move(str(item), str(target_item))
                                
                                # ë¹ˆ ë””ë ‰í† ë¦¬ ì‚­ì œ
                                if not any(dir_path.iterdir()):
                                    dir_path.rmdir()
                            else:
                                shutil.move(str(dir_path), str(target_dir))
                            
                            consolidated_count += 1
                            self.reorganize_log.append(f"ë””ë ‰í† ë¦¬ í†µí•©: {dir_path.name} â†’ {consolidation['target']}")
                            
                        except (OSError, PermissionError, shutil.Error) as e:
                            print(f"âš ï¸ ë””ë ‰í† ë¦¬ í†µí•© ì‹¤íŒ¨: {dir_path.name} - {e}")
        
        print(f"âœ… ë””ë ‰í† ë¦¬ í†µí•© ì™„ë£Œ: {consolidated_count}ê°œ")
        return consolidated_count
    
    def create_project_readme(self):
        """í”„ë¡œì íŠ¸ README ì—…ë°ì´íŠ¸/ìƒì„±"""
        readme_path = self.project_root / 'README.md'
        
        readme_content = f"""# FCA (Fraud & Customer Analytics) Project

## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”
ê³ ê¸‰ ì‚¬ê¸° íƒì§€ ë° ê³ ê° ë¶„ì„ ì‹œìŠ¤í…œ

## ğŸ—ï¸ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
FCA/
â”œâ”€â”€ src/                    # í•µì‹¬ ì†ŒìŠ¤ ì½”ë“œ
â”‚   â”œâ”€â”€ fca/               # Python ë°±ì—”ë“œ ëª¨ë“ˆ
â”‚   â””â”€â”€ static_dashboard/  # ì •ì  ëŒ€ì‹œë³´ë“œ
â”œâ”€â”€ data/                  # ë°ì´í„° íŒŒì¼ë“¤
â”‚   â”œâ”€â”€ raw/              # ì›ë³¸ ë°ì´í„°
â”‚   â”œâ”€â”€ processed/        # ì „ì²˜ë¦¬ëœ ë°ì´í„°
â”‚   â””â”€â”€ models/           # í•™ìŠµëœ ëª¨ë¸
â”œâ”€â”€ tests/                # í…ŒìŠ¤íŠ¸ ì½”ë“œ
â”‚   â”œâ”€â”€ unit/             # ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ integration/      # í†µí•© í…ŒìŠ¤íŠ¸
â”‚   â””â”€â”€ e2e/              # E2E í…ŒìŠ¤íŠ¸
â”œâ”€â”€ docs/                 # ë¬¸ì„œ ë° ê°€ì´ë“œ
â”‚   â”œâ”€â”€ api/              # API ë¬¸ì„œ
â”‚   â”œâ”€â”€ guides/           # ì‚¬ìš© ê°€ì´ë“œ
â”‚   â””â”€â”€ reports/          # ë¶„ì„ ë¦¬í¬íŠ¸
â”œâ”€â”€ tools/                # ìœ í‹¸ë¦¬í‹° ë° ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ scripts/          # ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ notebooks/        # Jupyter ë…¸íŠ¸ë¶
â”‚   â””â”€â”€ utilities/        # ìœ í‹¸ë¦¬í‹° ë„êµ¬
â”œâ”€â”€ config/               # ì„¤ì • íŒŒì¼ë“¤
â”œâ”€â”€ logs/                 # ë¡œê·¸ íŒŒì¼ë“¤
â””â”€â”€ archive/              # ë°±ì—… ë° ì•„ì¹´ì´ë¸Œ
```

## ğŸš€ ì‹œì‘í•˜ê¸°

### ì„¤ì¹˜
```bash
pip install -r config/requirements.txt
```

### ì‹¤í–‰
```bash
# ëŒ€ì‹œë³´ë“œ ì‹¤í–‰
cd src/static_dashboard
python3 serve.py

# í—¬ìŠ¤ì²´í¬
python3 tools/scripts/automated_health_check.py
```

## ğŸ”§ ì£¼ìš” ë„êµ¬

- **í”„ë¡œì íŠ¸ ë¶„ì„**: `tools/scripts/optimization_analysis.py`
- **ë³´ì•ˆ ê°ì‚¬**: `tools/scripts/security_audit.py`
- **ì„±ëŠ¥ ìµœì í™”**: `tools/scripts/performance_optimizer.py`
- **í—¬ìŠ¤ì²´í¬**: `tools/scripts/automated_health_check.py`

## ğŸ“Š ê¸°ëŠ¥

- ğŸ” **ì‚¬ê¸° íƒì§€**: ì‹¤ì‹œê°„ ì‚¬ê¸° ê±°ë˜ íƒì§€
- ğŸ’¬ **ê°ì • ë¶„ì„**: ê³ ê° í”¼ë“œë°± ê°ì • ë¶„ì„
- ğŸ‘¥ **ê³ ê° ì´íƒˆ ì˜ˆì¸¡**: ì´íƒˆ ìœ„í—˜ ê³ ê° ì‹ë³„
- ğŸ“ˆ **ëŒ€ì‹œë³´ë“œ**: ì¸í„°ë™í‹°ë¸Œ ë¶„ì„ ëŒ€ì‹œë³´ë“œ

## ğŸ› ï¸ ê°œë°œ

### ì½”ë“œ í’ˆì§ˆ
```bash
# ë³´ì•ˆ ê°ì‚¬
python3 tools/scripts/security_audit.py

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
python3 -m pytest tests/

# ì½”ë“œ í¬ë§·íŒ…
black src/
```

### ëª¨ë‹ˆí„°ë§
```bash
# í—¬ìŠ¤ì²´í¬
python3 tools/scripts/automated_health_check.py

# ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
python3 tools/scripts/automated_health_check.py --daemon
```

## ğŸ“š ë¬¸ì„œ

- [ìµœì í™” ê°€ì´ë“œ](docs/guides/PROJECT_OPTIMIZATION_GUIDE.md)
- [API ë¬¸ì„œ](docs/api/)
- [ë°°í¬ ê°€ì´ë“œ](docs/guides/deployment/)

## ğŸ¤ ê¸°ì—¬

1. Fork the project
2. Create your feature branch
3. Commit your changes
4. Push to the branch
5. Open a Pull Request

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: {datetime.now().strftime('%Y-%m-%d')}  
**ë²„ì „**: 2.0.0
"""
        
        try:
            with open(readme_path, 'w', encoding='utf-8') as f:
                f.write(readme_content)
            print("âœ… README.md ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            return True
        except Exception as e:
            print(f"âš ï¸ README ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def generate_structure_report(self):
        """êµ¬ì¡° ì¬ì •ë¦¬ ë¦¬í¬íŠ¸ ìƒì„±"""
        report = {
            'reorganization_date': datetime.now().isoformat(),
            'changes_made': self.reorganize_log,
            'final_structure': {}
        }
        
        # ìµœì¢… êµ¬ì¡° ìŠ¤ìº”
        for item in self.project_root.iterdir():
            if item.is_dir() and not item.name.startswith('.'):
                report['final_structure'][item.name] = {
                    'file_count': len(list(item.rglob('*'))),
                    'size_mb': self._get_dir_size(item)
                }
        
        report_path = self.project_root / 'structure_reorganization_report.json'
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“Š êµ¬ì¡° ì¬ì •ë¦¬ ë¦¬í¬íŠ¸ ì €ì¥: {report_path}")
        return report
    
    def run_full_reorganization(self):
        """ì „ì²´ êµ¬ì¡° ì¬ì •ë¦¬ ì‹¤í–‰"""
        print("ğŸ—ï¸ FCA í”„ë¡œì íŠ¸ êµ¬ì¡° ì¬ì •ë¦¬ ì‹œì‘")
        print("=" * 50)
        
        # 1. í˜„ì¬ êµ¬ì¡° ë¶„ì„
        current_structure, root_files = self.analyze_current_structure()
        
        # 2. í‘œì¤€ ë””ë ‰í† ë¦¬ ìƒì„±
        created_dirs = self.create_target_directories()
        
        # 3. ë£¨íŠ¸ íŒŒì¼ ì¬ì •ë¦¬
        moved_files = self.reorganize_root_files()
        
        # 4. ìœ ì‚¬í•œ ë””ë ‰í† ë¦¬ í†µí•©
        consolidated = self.consolidate_similar_directories()
        
        # 5. README ì—…ë°ì´íŠ¸
        self.create_project_readme()
        
        # 6. ë¦¬í¬íŠ¸ ìƒì„±
        report = self.generate_structure_report()
        
        print("\nâœ… í”„ë¡œì íŠ¸ êµ¬ì¡° ì¬ì •ë¦¬ ì™„ë£Œ!")
        print(f"ğŸ“ ìƒì„±ëœ ë””ë ‰í† ë¦¬: {len(created_dirs)}ê°œ")
        print(f"ğŸ“„ ì´ë™ëœ íŒŒì¼: {len(moved_files)}ê°œ")
        print(f"ğŸ”„ í†µí•©ëœ ë””ë ‰í† ë¦¬: {consolidated}ê°œ")
        print(f"ğŸ“Š ì´ ë³€ê²½ì‚¬í•­: {len(self.reorganize_log)}ê°œ")
        
        return report

if __name__ == "__main__":
    reorganizer = FCAStructureReorganizer()
    reorganizer.run_full_reorganization()